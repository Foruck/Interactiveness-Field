# * Utilities
output_dir: logs # path where to save, empty for no saving
pretrained: params/detr-r50-pre-hico.pth # Pretrained model path
start_epoch: 0 # start epoch
resume: '' # resume from checkpoint
device: cuda # device to use for training / testing
seed: 42
eval: false
num_workers: 2

lr: 1e-4
lr_backbone: 1e-5
batch_size: 2
weight_decay: 1e-4
epochs: 150
lr_drop: 100
clip_max_norm: 0.1 # gradient clipping max norm

# * Model parameters
frozen_weights: # Path to the pretrained model. If set, only the mask head will be trained

# * Backbone
backbone: resnet50 # Name of the convolutional backbone to use
dilation: false # If true, we replace stride with dilation in the last convolutional block (DC5)
position_embedding: sine # ('sine', 'learned'), Type of positional embedding to use on top of the image features

# * Transformer
enc_layers: 6 # Number of encoding layers in the transformer
dec_layers: 6 # Number of decoding layers in the transformer
dim_feedforward: 2048 # intermediate size of the feedforward layers in the transformer blocks
hidden_dim: 256 # Size of the embeddings (dimension of the transformer)
dropout: 0.1 # Dropout applied in the transformer
nheads: 8 # Number of attention heads inside the transformer's attentions
num_queries: 100  # Number of query slots
pre_norm: false
aux_loss: true # Disables auxiliary decoding losses (loss at each layer)")
# xinpeng added
binary: false # Binary interactiveness detection
cascaded: false  # Cascaded decoder
dec_layers_box: 3 # Number of box decoding layers in the cascaded transformer
dec_layers_verb: 3 # Number of verb decoding layers in the cascaded transformer
                        

# * Segmentation
masks: false # Train segmentation head if the flag is provided

# * HOI
hoi: true # Train for HOI if the flag is provided
num_obj_classes: 80 # Number of object classes
num_verb_classes: 117 # Number of verb classes
subject_category_id: 0
verb_loss_type: focal # (bce, focal), Loss type for the verb classification

# * Matcher
set_cost_class: 1 # Class coefficient in the matching cost
set_cost_bbox: 2.5 # L1 box coefficient in the matching cost
set_cost_giou: 1 # giou box coefficient in the matching cost
set_cost_obj_class: 1 # Object class coefficient in the matching cost
set_cost_verb_class: 1 # Verb class coefficient in the matching cost
# xinpeng added
set_cost_binary: 1 # Binary class coefficient in the matching cost

# * Loss coefficients
mask_loss_coef: 1
dice_loss_coef: 1
bbox_loss_coef: 2.5
giou_loss_coef: 1
obj_loss_coef: 1
verb_loss_coef: 1
eos_coef: 0.1 # Relative classification weight of the no-object class
# xinpeng added
bin_loss_coef: 1

# dataset parameters
dataset_file: hico 
coco_path:
coco_panoptic_path:
remove_difficult: false
hoi_path: data/hico_20160224_det


# * distributed training parameters
world_size: 1 # number of distributed processes
dist_url: 'env://' # url used to set up distributed training